{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "# Get active Snowflake session\n",
    "session = get_active_session()\n",
    "\n",
    "# Determine database and schema dynamically\n",
    "current_context_df = session.sql(\"SELECT current_database() AS DATABASE_NAME, current_schema() AS SCHEMA_NAME\").to_pandas()\n",
    "database_name = current_context_df.iloc[0, 0]\n",
    "schema_name = current_context_df.iloc[0, 1]\n",
    "\n",
    "ENV = schema_name.split('_')[0]  # Extract environment prefix\n",
    "\n",
    "# Define target schema for raw data\n",
    "target_schema = f\"{ENV}_RAW_SCHEMA\"\n",
    "\n",
    "# Create CSV file format in the target schema\n",
    "create_file_format_sql = f\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT {target_schema}.CSV_FORMAT\n",
    "    TYPE = 'CSV'\n",
    "    FIELD_DELIMITER = ','\n",
    "    PARSE_HEADER = TRUE\n",
    "    SKIP_BLANK_LINES = TRUE\n",
    "    TRIM_SPACE = TRUE\n",
    "    ENCODING = 'UTF-8'\n",
    "    NULL_IF = ('.', 'NULL', 'null', '');\n",
    "\"\"\"\n",
    "session.sql(create_file_format_sql).collect()\n",
    "\n",
    "# Define NOAA S3 bucket structure\n",
    "stages = {\n",
    "    \"NOAA_WEATHER_RAW_STAGE\": \"s3://noaaclimatedata/weatherData/\"\n",
    "}\n",
    "\n",
    "# Create external stage for NOAA data\n",
    "for stage, s3_path in stages.items():\n",
    "    create_stage_sql = f\"\"\"\n",
    "    CREATE OR REPLACE STAGE {target_schema}.{stage}\n",
    "    STORAGE_INTEGRATION = noaa_s3_integration\n",
    "    URL = '{s3_path}'\n",
    "    FILE_FORMAT = {target_schema}.CSV_FORMAT;\n",
    "    \"\"\"\n",
    "    session.sql(create_stage_sql).collect()\n",
    "\n",
    "# List files in the stage and load them into tables\n",
    "for stage in stages:\n",
    "    files = session.sql(f\"LIST @{target_schema}.{stage};\").collect()\n",
    "    if not files:\n",
    "        print(\"  No files found in stage.\")\n",
    "        continue\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = file[0]  # Full file path in S3\n",
    "        file_size = file[1]  # File size in bytes\n",
    "        file_name = os.path.basename(file_path).split(\".\")[0].upper()\n",
    "        \n",
    "        print(f\"  {file_path} (Size: {file_size} bytes)\")\n",
    "\n",
    "        # Create table in the target schema\n",
    "        create_table_sql = f\"\"\"\n",
    "        CREATE OR REPLACE TABLE {database_name}.{target_schema}.{file_name} (\n",
    "            STATION STRING,\n",
    "            DATE DATE,\n",
    "            TEMP FLOAT,\n",
    "            PRECIP FLOAT,\n",
    "            WIND_SPEED FLOAT\n",
    "        );\n",
    "        \"\"\"\n",
    "        session.sql(create_table_sql).collect()\n",
    "        print(f\"✅ Created table: {file_name} in {target_schema}\")\n",
    "        \n",
    "        # Load data from the S3 stage into the table\n",
    "        copy_into_sql = f\"\"\"\n",
    "        COPY INTO {database_name}.{target_schema}.{file_name} \n",
    "        FROM @{target_schema}.{stage}/{file_name}\n",
    "        FILE_FORMAT = {target_schema}.CSV_FORMAT\n",
    "        MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;\n",
    "        \"\"\"\n",
    "        session.sql(copy_into_sql).collect()\n",
    "        print(f\"✅ Data loaded into {target_schema}.{file_name}\")\n",
    "        \n",
    "        # Update table to replace NULLs (from '.') with 0\n",
    "        update_sql = f\"\"\"\n",
    "        UPDATE {database_name}.{target_schema}.{file_name}\n",
    "        SET TEMP = 0 WHERE TEMP IS NULL;\n",
    "        \"\"\"\n",
    "        session.sql(update_sql).collect()\n",
    "        print(f\"✅ Updated {file_name}: replaced NULL with 0 in TEMP column\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
